# Adjacency lists vs watched literals
The following results were generated by the command `Kresat benchmark -a cdcl datasets/`.
The parameters for clause deletion and restarts were set to their defaults:
`luby unit run constant = 100, multiplier = 1.1, initial cache size = 10 000`.

The results are rounded to 4 decimal places and averaged over all instances.

## 3-SAT instances
| Dataset     |     Adjacency avg (sec)  |   Watched avg (sec)    |
| -----       |        :--------:        |    :-------:           |
| [uf50](https://www.cs.ubc.ca/~hoos/SATLIB/Benchmarks/SAT/RND3SAT/descr.html)        |       0.0005          |       0.0006            |
| uuf50       |          0.0011          |         0.0014         |
| uf75        |          0.0049          |         0.0052         |
| uuf75       |          0.0117          |         0.0119         |
| uf100       |          0.0646          |         0.043          |
| uuf100      |          0.2723          |         0.142          |
| uf125       |          1.4955          |         0.4984         |
| uuf125      |          5.3507          |         1.5731         |

## Other SAT instances
| Dataset     |     Adjacency avg (sec)  |   Watched avg (sec)    |
| -----       |        :--------:        |    :-------:           |
| [ais](https://www.cs.ubc.ca/~hoos/SATLIB/Benchmarks/SAT/AIS/descr.html)         |    47.9121                   |    14.578            |
| [flat150](https://www.cs.ubc.ca/~hoos/SATLIB/Benchmarks/SAT/GCP/descr.html)     |     1.2367     |   0.5372     |
| [jnh](https://www.cs.ubc.ca/~hoos/SATLIB/Benchmarks/SAT/DIMACS/JNH/descr.html)         |   0.0198          | 0.016   |
| [hanoi](https://www.cs.ubc.ca/~hoos/SATLIB/Benchmarks/SAT/DIMACS/HANOI/descr.html) |    0.7553    |      1.088 |
|  [pret](https://www.cs.ubc.ca/~hoos/SATLIB/Benchmarks/SAT/DIMACS/PRET/descr.html)  |   0.0172     |     0.0154 |

This is a selection of datasets (from [the same page](https://www.cs.ubc.ca/~hoos/SATLIB/benchm.html))
which managed to finish on my testing machine in a reasonable enough time.

## Evaluation
As can be seen from the results in the first table, CDCL seems to run way faster with watched literals than DPLL did.
CDCL also appears to scale better with the size of 3-SAT instances.

In the case of random (other) SAT instances, CDCL sometimes manages to finish in a reasonable time where DPLL couldn't (e.g. `hanoi`)
while in other cases it takes tremendously more time to finish (e.g. in `ais`).
